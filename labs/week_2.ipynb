{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06684a08-2d20-4c3a-bbd8-a6770d89f48c",
   "metadata": {},
   "source": [
    "### Week 2 : Images as Signals & Noise removal\n",
    "\n",
    "#### Date : 14th October, 2021\n",
    "\n",
    "* This lab session is  is broken down into two sections, the first is just a visual demonstration therefore all you need to do is copy & paste or type out the code from task 1 and run each section.\n",
    "\n",
    "* The second part requires you to code your own example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c23b78-79f2-4d24-9b66-40b6d32c783f",
   "metadata": {},
   "source": [
    "#### Fourier Transform:\n",
    "\n",
    "* We can use Fourier transforms to decompose an image into its sine and cosine components, resulting in an image in its frequency domain rather than its spatial domain. This has many implications and applications which will be discussed in class.\n",
    "\n",
    "* Today however we wanted to demonstrate visually this decomposition process. Please note that we are showing you the signal decomposition by taking a 1D slice of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e0776-e709-413e-b154-8a85778bd5a0",
   "metadata": {},
   "source": [
    "#### Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4642f5c-8a05-42e7-ab65-bf9a51f1968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ac626-7ab7-42cf-9edc-26e23fec2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv2.imread('../images/sample_image.jpg', cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44592a56-658d-4b4a-a63f-dca664365161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to double and gray scale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "img_gray = img_gray.astype(np.double) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96c604-7fcd-48d1-adfa-260d0c1d814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_gray)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd797b6-d621-41b5-8b2e-4fa570ea02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we take a sample of this image\n",
    "row = img_gray.shape[1] // 2\n",
    "x = img_gray[row, :]\n",
    "plt.plot(x)\n",
    "plt.title('Grey-level profile at ' + str(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f8aa4-ce89-4fd8-b900-52ec7d0f7cf6",
   "metadata": {},
   "source": [
    "Here, we plot the amplitude of these frequencies which is found by taking the absolute value of our FFT signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42a3a3-a99c-4a74-965d-85d7ec1c2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.fft.fft(x)\n",
    "N = len(x)\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.title.set_text('Amplitudes as a function of frequency')\n",
    "plt.plot(np.abs(X))\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax2.title.set_text('Phase as a function of frequency')\n",
    "theta = np.arctan2(np.imag(X), np.real(X))\n",
    "plt.plot(theta)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.title.set_text('Real part as a function of frequency')\n",
    "plt.plot(np.real(X))\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "ax4.title.set_text('Imaginary part as a function of frequency')\n",
    "plt.plot(np.imag(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46aa528-e3e4-412a-86a7-ba4f79384852",
   "metadata": {},
   "source": [
    "Next we are going to see the individual components that make up this signal, showing just a sub sample of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabf4a7-d4ce-49d7-a6b4-97acc16c0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "reconstruction = 0.\n",
    "p = 2 * np.pi * np.arange(N) / N # 0 to 2*pi\n",
    "check_points = [i for i in range(0, 4)] + [i for i in range(4, N - 4, 16)] + [i for i in range(N - 4, N)]\n",
    "\n",
    "for k in range(0, N):\n",
    "    # decompose X[k] into magnitude and phase\n",
    "    a = np.abs(X[k])\n",
    "    theta = np.arctan2(np.imag(X[k]), np.real(X[k]))\n",
    "    phi = k * p + theta\n",
    "    component = a * np.cos(phi) / N\n",
    "    reconstruction += component\n",
    "    if k in check_points:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(6,8))\n",
    "        \n",
    "        ax[0].plot(component)\n",
    "        ax[0].set_title('Spatial frequency ' + str(k) + ' cycles across the image')\n",
    "        \n",
    "        ax[1].plot(reconstruction, alpha=0.5, label='reconstruction')\n",
    "        ax[1].plot(x, alpha=0.5, label='GT')\n",
    "        ax[1].legend()\n",
    "        ax[1].set_title('reconstruction until ' + str(k))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc4b5e8-64f5-459c-b76a-f02298ada897",
   "metadata": {},
   "source": [
    "### Task 2: Noise removal\n",
    "\n",
    "* For those of you who have experienced taking images in low lighting conditions you will inevitably have come across issues with noise, this is usually caused by having to use a very high ISO level. \n",
    "\n",
    "* The ISO setting is used to control the speed of the camera by amplifying the sensitivity of the cameras sensor.\n",
    " \n",
    "* Today we will code two simple techniques that can be used to remove or reduce this noise. This does come at a price however by removing some fine details, as you will see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d1b2d3-1e80-4045-a0c1-8a103dfa4dba",
   "metadata": {},
   "source": [
    "#### Median Filter\n",
    "\n",
    "* Your first task is to write a Median Filter. To start off with I would advise that you work on gray scale images. Once you manage this you can then figure out how to apply this to a colour image.\n",
    "\n",
    "* The median filter works by iterating over an image using a sliding window (you can set the size, I would recommend something like 3x3 or 5x5). Each pixel will be replaced with the median pixel value of the values in the box. \n",
    "\n",
    "* Given this below matrix\n",
    "\n",
    "$$\\begin{bmatrix} 128 & 50 & 120 \\\\ 10 & \\color{Red}{214} & 150 \\\\ 127 & 157 & 137 \\end{bmatrix}$$\n",
    "\n",
    "* After the median filter, the 214 would be replaced by the median value - 128\n",
    "\n",
    "* Please implement your code using numpy only - compare the result with opencv later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e1d68-c261-4158-a20a-40064453205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6,10))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('GT')\n",
    "# ax[1].imshow(your_image)\n",
    "# ax[1].set_title('Median Blurred')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7e830-6c03-4538-b4ed-3de054b47c04",
   "metadata": {},
   "source": [
    "#### Adaptive Filter\n",
    "\n",
    "* Once you have completed the median filter on a colour image applying an Adaptive filter will be very easy. \n",
    "\n",
    "* This time all you need to do is compute the new pixel taking its variance into account and thus helping to preserve edges and details. This can be done using the following formula:\n",
    "\n",
    "* Mean: \n",
    "\n",
    "$$\\mu_{i, j} = \\frac{1}{|\\mathcal{K}_{i,j}|}\\sum_{n_1, n_2 \\in \\mathcal{K}_{i,j}} \\mathcal{K}_{i,j}(n_1, n_2)$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Variance:\n",
    "\n",
    "$$\\sigma^2_{i, j} = \\frac{1}{|\\mathcal{K}_{i, j}|}\\sum_{n_1, n_2 \\in \\mathcal{K}_{i,j}} (\\mathcal{K}_{i,j}(n_1, n_2) - \\mu_{i, j})^2$$\n",
    "\n",
    "* Output Pixel:\n",
    "\n",
    "$$I(i, j) = \\mu_{i, j} + \\max(\\frac{\\sigma^2_{i, j} - v^2_{i, j}}{\\sigma^2_{i, j}}, 0)(\\mathcal{K}_{i,j}(n_1, n_2)-\\mu_{i, j})$$   \n",
    "\n",
    "\n",
    "where $\\mathcal{K}$ is a (n, n) kernel. $v^2$ is the noise variance and can be eiter specified by the user or taken as the average of all local estimated variances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7b410",
   "metadata": {},
   "source": [
    "Question: Think about why we need $\\max(\\frac{\\sigma^2_{i, j} - v^2_{i, j}}{\\sigma^2_{i, j}}, 0)$ instead of using $\\frac{\\sigma^2_{i, j} - v^2_{i, j}}{\\sigma^2_{i, j}}$ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73901311-0586-4bc5-972b-40e2773ed826",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_img = cv2.imread('../images/formula_adaptive_filter.png')\n",
    "plt.title('Adaptive Filter Formula')\n",
    "plt.imshow(formula_img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939d4c4-3033-4709-841a-6166c69cb492",
   "metadata": {},
   "source": [
    "* Please refer to the commented matlab code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0a0d9-b5a1-47a7-948b-47a4081c2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function outimg = adaptiveFilter(img, varargin)\n",
    "# [sx, sy, ~] = size(img);\n",
    "# %create output image\n",
    "# outimg = zeros(sx,sy,1);\n",
    "\n",
    "# if length(varargin) > 1\n",
    "#     GRID_SIZE = varargin{1};\n",
    "# else\n",
    "#     GRID_SIZE = 3;\n",
    "# end\n",
    "\n",
    "# paddedimg = padarray(img, [floor(GRID_SIZE/2) floor(GRID_SIZE/2)], 'replicate');\n",
    "\n",
    "# if length(varargin) > 1\n",
    "#     v  = varargin{2};\n",
    "# else\n",
    "#     %v  = 5;\n",
    "#     temp = zeros(sx,sy);\n",
    "#     for i = round(GRID_SIZE/2):(sx+floor(GRID_SIZE/2))\n",
    "#         for j = round(GRID_SIZE/2):(sy+floor(GRID_SIZE/2))\n",
    "#             list_of_pixels = paddedimg(i-floor(GRID_SIZE/2):i+floor(GRID_SIZE/2) ...\n",
    "#             , j-floor((GRID_SIZE)/2):j+floor((GRID_SIZE)/2), :);\n",
    "#              %find intensity values\n",
    "#              list_of_pixels = list_of_pixels(:);\n",
    "#              temp(i,j) = var(double(list_of_pixels));\n",
    "#         end\n",
    "#     end\n",
    "#     v = mean(temp(:));\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %iterate through all of the pixels\n",
    "# for i = round(GRID_SIZE/2):(sx+floor(GRID_SIZE/2))\n",
    "#     for j = round(GRID_SIZE/2):(sy+floor(GRID_SIZE/2))\n",
    "#         %use our grid to find median result\n",
    "#         list_of_pixels = paddedimg(i-floor(GRID_SIZE/2):i+floor(GRID_SIZE/2) ...\n",
    "#             , j-floor((GRID_SIZE)/2):j+floor((GRID_SIZE)/2), :);\n",
    "#         %find intensity values\n",
    "#         list_of_pixels = list_of_pixels(:);\n",
    "#         mean_pixel = mean(list_of_pixels);\n",
    "#         var_pixel = var(double(list_of_pixels));\n",
    "#         outimg(i-floor(GRID_SIZE/2),j-floor(GRID_SIZE/2)) = mean_pixel + ( (var_pixel - v)/var_pixel )* (paddedimg(i,j) - mean_pixel);\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125270e-e1f6-490b-a5a2-dc94309ab719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One answer\n",
    "fig, axes = plt.subplots(1,2,figsize=(6,10))\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('GT')\n",
    "# axes[1].imshow(your adaptive image)\n",
    "# axes[1].set_title('Adaptive Filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cc65d-3c8c-4f7b-a122-17c57e0a2c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4af53f3-071b-4619-918b-9334894ae47d",
   "metadata": {},
   "source": [
    "#### Filtering vectorized\n",
    "\n",
    "* Using as little number of for-loops as possible, perform median filtering on the colour input.\n",
    "\n",
    "* The vectorized down-sampling code from last week could be a good start. Try to pre-calculate the filter kernel (the array of weights) and use the .* operator to multiply 1-D arrays with each other.\n",
    "\n",
    "* How much space does your method need for an 11x11 median filtering on a 3 channel (uint8)image? \n",
    "\n",
    "* Using the package - *time* does your algorithm compare to the built-in median filtering of opencv? Also, measure the difference between your implementation and opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ad648-aa3b-4e01-af23-b527fecba9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
